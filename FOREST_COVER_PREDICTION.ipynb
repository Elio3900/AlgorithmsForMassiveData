{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FOREST_COVER_PREDICTION.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GrzegorzMeller/AlgorithmsForMassiveData/blob/master/FOREST_COVER_PREDICTION.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmEnlV9WRc3N",
        "colab_type": "text"
      },
      "source": [
        "# Exercises 30/04\n",
        "\n",
        "In the 30/04 lab lecture we will focus on data scaling.\n",
        "\n",
        "Data scaling is a common preprocessing that is performed on datasets where data is represented with different scales.\n",
        "\n",
        "Several scaling methods are available, where the most common are:\n",
        "\n",
        "- Normalization. It is basically a rescaling of the data so that the values are within the range $[0,1]$.\n",
        "- Standardization. It consists of rescaling the distribution of the observed values to zero mean and unit standard deviation. In the literature, this process is sometimes referred to as *whitening*.\n",
        "\n",
        "In the lab lecture we will see how to perform data scaling and why data scaling is important for neural networks.\n",
        "\n",
        "Meanwhile, address the following exercises."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIgecVlbVI7M",
        "colab_type": "text"
      },
      "source": [
        "# Neural network models\n",
        "\n",
        "Build three feed-forward neural network models with one or more layers as follows:\n",
        "- first network: use the original raw data,\n",
        "- second network: use normalized data,\n",
        "- third network: use standardized data.\n",
        "\n",
        "Do not use convolutional layers. Exploit the methods we saw in the last lab lecture to properly train the networks (for instance, techniques to avoid overfitting). use TensorBoard to assess the performance.\n",
        "\n",
        "Finally, address the following questions:\n",
        "- Which network reaches the best performance?\n",
        "- Do you notice the difference in performance when scaling the data?\n",
        "- Which scaling method is the best? Can you guess why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7_WxyK-SzDh",
        "colab_type": "text"
      },
      "source": [
        "# Forest Cover Type Prediction dataset\n",
        "\n",
        "Download the Forest Cover Type Prediction dataset.\n",
        "\n",
        "The dataset contains tree observations from four areas of the Roosevelt National Forest in Colorado. All observations are cartographic variables (no remote sensing) from 30 meter x 30 meter sections of forest. The task is to predict the forest cover type (the predominant kind of tree cover) from strictly cartographic variables (as opposed to remotely sensed data). More info related to the dataset are available [here](https://www.kaggle.com/uciml/forest-cover-type-dataset).\n",
        "\n",
        "Download the dataset in the Google Colab environment using ``curl`` as follows:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbEe8zcsS6UB",
        "colab_type": "code",
        "outputId": "b5fc5298-0645-4a5c-b644-e1f9d5fe0928",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "!curl http://bodini.di.unimi.it/teaching/ADM_files/covtype.csv --output covtype.csv"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 71.6M  100 71.6M    0     0  9337k      0  0:00:07  0:00:07 --:--:-- 17.6M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lbelrq8mTjKw",
        "colab_type": "text"
      },
      "source": [
        "Then, read the .csv file containing the dataset with Pandas as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVgv1Z4mTdXh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('covtype.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I11xn52SUXqg",
        "colab_type": "text"
      },
      "source": [
        "The last column contains the labels, while the other columns contain the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twtCXrI-Uf6i",
        "colab_type": "code",
        "outputId": "86dac23a-1ca0-48ae-fdb8-9a94a9ab35b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "source": [
        "x = df[df.columns[:-1]]\n",
        "y = df.Cover_Type\n",
        "#print(df)\n",
        "print(x)\n",
        "print(y.drop_duplicates())\n",
        "print(x.shape[1])"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        Elevation  Aspect  Slope  ...  Soil_Type38  Soil_Type39  Soil_Type40\n",
            "0            2596      51      3  ...            0            0            0\n",
            "1            2590      56      2  ...            0            0            0\n",
            "2            2804     139      9  ...            0            0            0\n",
            "3            2785     155     18  ...            0            0            0\n",
            "4            2595      45      2  ...            0            0            0\n",
            "...           ...     ...    ...  ...          ...          ...          ...\n",
            "581007       2396     153     20  ...            0            0            0\n",
            "581008       2391     152     19  ...            0            0            0\n",
            "581009       2386     159     17  ...            0            0            0\n",
            "581010       2384     170     15  ...            0            0            0\n",
            "581011       2383     165     13  ...            0            0            0\n",
            "\n",
            "[581012 rows x 54 columns]\n",
            "0       5\n",
            "2       2\n",
            "40      1\n",
            "1654    7\n",
            "1818    3\n",
            "1868    6\n",
            "1988    4\n",
            "Name: Cover_Type, dtype: int64\n",
            "54\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-QKbh2pTrup",
        "colab_type": "text"
      },
      "source": [
        "Divide the dataset in train and test sets. To compare with my results, set 0.7 as the training set ratio and ``random_state = 90``. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDg0NvwYTod5",
        "colab_type": "code",
        "outputId": "9b3d8a79-f417-4cbd-ed2b-d8b92e36946d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y , train_size = 0.7, random_state = 90)\n",
        "print(x_train.shape,y_train.shape, x_test.shape, y_test.shape)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(406708, 54) (406708,) (174304, 54) (174304,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQRACSRHK0lO",
        "colab_type": "code",
        "outputId": "c27d03fb-4eeb-4c30-b053-826631ddbf1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "#one-hot encoding for outputs\n",
        "y_train = tf.reshape(tf.one_hot(y_train, 7),[406708, 7])\n",
        "y_test = tf.reshape(tf.one_hot(y_test, 7),[174304, 7])\n",
        "\n",
        "print(y_test, y_train)\n",
        "print(y_train.shape, y_test.shape)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]], shape=(174304, 7), dtype=float32) tf.Tensor(\n",
            "[[0. 0. 1. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]], shape=(406708, 7), dtype=float32)\n",
            "(406708, 7) (174304, 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_e-X7KfA_bQ",
        "colab_type": "code",
        "outputId": "714c27c8-a33b-4e4a-af77-2120f21ca44b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "#neural network implementation\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(200, activation=\"relu\", input_shape=(x_train.shape[1],)), \n",
        "\n",
        "    keras.layers.Dense(60, activation=\"relu\"), # 2nd hidden layer\n",
        "    keras.layers.Dropout(0.4),\n",
        "\n",
        "    keras.layers.Dense(7, activation=\"softmax\")]) #  output layer with 7 categories\n",
        "  \n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.SGD(lr=0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_33 (Dense)             (None, 200)               11000     \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 60)                12060     \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 60)                0         \n",
            "_________________________________________________________________\n",
            "dense_35 (Dense)             (None, 7)                 427       \n",
            "=================================================================\n",
            "Total params: 23,487\n",
            "Trainable params: 23,487\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2y_MNKHecXY4",
        "colab_type": "code",
        "outputId": "7df46975-bd84-4e05-c4b7-235a69fa151b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "#TASK 3: data rescaling\n",
        "from sklearn import preprocessing\n",
        "\n",
        "#Select numerical columns which needs to be normalized\n",
        "train_norm = x_train[x_train.columns[0:10]]\n",
        "test_norm = x_test[x_test.columns[0:10]]\n",
        "\n",
        "# Normalize Training Data \n",
        "std_scale = preprocessing.StandardScaler().fit(train_norm)\n",
        "x_train_norm = std_scale.transform(train_norm)\n",
        "\n",
        "#Converting numpy array to dataframe\n",
        "training_norm_col = pd.DataFrame(x_train_norm, index=train_norm.index, columns=train_norm.columns) \n",
        "x_train.update(training_norm_col)\n",
        "print (x_train.head())\n",
        "\n",
        "# Normalize Testing Data by using mean and SD of training set\n",
        "x_test_norm = std_scale.transform(test_norm)\n",
        "testing_norm_col = pd.DataFrame(x_test_norm, index=test_norm.index, columns=test_norm.columns) \n",
        "x_test.update(testing_norm_col)\n",
        "print (x_test.head())"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:5732: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self[col] = expressions.where(mask, this, that)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "        Elevation    Aspect     Slope  ...  Soil_Type38  Soil_Type39  Soil_Type40\n",
            "152044   0.222366 -0.228639 -0.412503  ...            0            0            0\n",
            "363373   1.980490 -0.469989  0.255453  ...            0            0            1\n",
            "372733  -1.081933  0.271939  0.389044  ...            0            0            0\n",
            "572846  -1.164122 -0.157128 -0.278912  ...            0            0            0\n",
            "114145  -0.052787  0.861906  0.255453  ...            0            0            0\n",
            "\n",
            "[5 rows x 54 columns]\n",
            "        Elevation    Aspect     Slope  ...  Soil_Type38  Soil_Type39  Soil_Type40\n",
            "204886   0.783394 -1.310245 -0.946867  ...            0            0            0\n",
            "116027  -0.903262 -1.006323 -0.679685  ...            0            0            0\n",
            "328145  -0.270766 -1.095711 -0.278912  ...            0            0            0\n",
            "579670  -1.139108 -0.961628 -0.412503  ...            0            0            0\n",
            "41341    0.265247  0.736762 -1.347641  ...            0            0            0\n",
            "\n",
            "[5 rows x 54 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:5732: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self[col] = expressions.where(mask, this, that)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVa1ddXOdFdz",
        "colab_type": "code",
        "outputId": "d73a60c2-26fe-458c-a656-c1ce427a4571",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        }
      },
      "source": [
        "history1 = model.fit(x_train,\n",
        "                    y_train,\n",
        "                    batch_size=100,\n",
        "                    epochs=30,\n",
        "                    validation_data=(x_test,y_test),\n",
        "                    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss')],\n",
        "                    )"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "4068/4068 [==============================] - 12s 3ms/step - loss: 1.1469 - accuracy: 0.5027 - val_loss: 0.8582 - val_accuracy: 0.6383\n",
            "Epoch 2/30\n",
            "4068/4068 [==============================] - 12s 3ms/step - loss: 0.8356 - accuracy: 0.6232 - val_loss: 0.7354 - val_accuracy: 0.6832\n",
            "Epoch 3/30\n",
            "4068/4068 [==============================] - 12s 3ms/step - loss: 0.7561 - accuracy: 0.6605 - val_loss: 0.6838 - val_accuracy: 0.6958\n",
            "Epoch 4/30\n",
            "4068/4068 [==============================] - 12s 3ms/step - loss: 0.7183 - accuracy: 0.6769 - val_loss: 0.6589 - val_accuracy: 0.7024\n",
            "Epoch 5/30\n",
            "4068/4068 [==============================] - 12s 3ms/step - loss: 0.6964 - accuracy: 0.6856 - val_loss: 0.6427 - val_accuracy: 0.7062\n",
            "Epoch 6/30\n",
            "4068/4068 [==============================] - 12s 3ms/step - loss: 0.6803 - accuracy: 0.6915 - val_loss: 0.6313 - val_accuracy: 0.7090\n",
            "Epoch 7/30\n",
            "4068/4068 [==============================] - 12s 3ms/step - loss: 0.6684 - accuracy: 0.6962 - val_loss: 0.6218 - val_accuracy: 0.7116\n",
            "Epoch 8/30\n",
            "4068/4068 [==============================] - 12s 3ms/step - loss: 0.6595 - accuracy: 0.6989 - val_loss: 0.6150 - val_accuracy: 0.7135\n",
            "Epoch 9/30\n",
            "4068/4068 [==============================] - 12s 3ms/step - loss: 0.6526 - accuracy: 0.7019 - val_loss: 0.6082 - val_accuracy: 0.7150\n",
            "Epoch 10/30\n",
            "4068/4068 [==============================] - 12s 3ms/step - loss: 0.6488 - accuracy: 0.7031 - val_loss: 0.6038 - val_accuracy: 0.7159\n",
            "Epoch 11/30\n",
            "4068/4068 [==============================] - 12s 3ms/step - loss: 0.6486 - accuracy: 0.7030 - val_loss: 0.5998 - val_accuracy: 0.7167\n",
            "Epoch 12/30\n",
            "4068/4068 [==============================] - 12s 3ms/step - loss: 0.6517 - accuracy: 0.7016 - val_loss: 0.5955 - val_accuracy: 0.7167\n",
            "Epoch 13/30\n",
            "4068/4068 [==============================] - 12s 3ms/step - loss: 0.6596 - accuracy: 0.6972 - val_loss: 0.5977 - val_accuracy: 0.7138\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}