{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FOREST_COVER_PREDICTION.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GrzegorzMeller/AlgorithmsForMassiveData/blob/master/FOREST_COVER_PREDICTION.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmEnlV9WRc3N",
        "colab_type": "text"
      },
      "source": [
        "# Exercises 30/04\n",
        "\n",
        "In the 30/04 lab lecture we will focus on data scaling.\n",
        "\n",
        "Data scaling is a common preprocessing that is performed on datasets where data is represented with different scales.\n",
        "\n",
        "Several scaling methods are available, where the most common are:\n",
        "\n",
        "- Normalization. It is basically a rescaling of the data so that the values are within the range $[0,1]$.\n",
        "- Standardization. It consists of rescaling the distribution of the observed values to zero mean and unit standard deviation. In the literature, this process is sometimes referred to as *whitening*.\n",
        "\n",
        "In the lab lecture we will see how to perform data scaling and why data scaling is important for neural networks.\n",
        "\n",
        "Meanwhile, address the following exercises."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIgecVlbVI7M",
        "colab_type": "text"
      },
      "source": [
        "# Neural network models\n",
        "\n",
        "Build three feed-forward neural network models with one or more layers as follows:\n",
        "- first network: use the original raw data,\n",
        "- second network: use normalized data,\n",
        "- third network: use standardized data.\n",
        "\n",
        "Do not use convolutional layers. Exploit the methods we saw in the last lab lecture to properly train the networks (for instance, techniques to avoid overfitting). use TensorBoard to assess the performance.\n",
        "\n",
        "Finally, address the following questions:\n",
        "- Which network reaches the best performance?\n",
        "- Do you notice the difference in performance when scaling the data?\n",
        "- Which scaling method is the best? Can you guess why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7_WxyK-SzDh",
        "colab_type": "text"
      },
      "source": [
        "# Forest Cover Type Prediction dataset\n",
        "\n",
        "Download the Forest Cover Type Prediction dataset.\n",
        "\n",
        "The dataset contains tree observations from four areas of the Roosevelt National Forest in Colorado. All observations are cartographic variables (no remote sensing) from 30 meter x 30 meter sections of forest. The task is to predict the forest cover type (the predominant kind of tree cover) from strictly cartographic variables (as opposed to remotely sensed data). More info related to the dataset are available [here](https://www.kaggle.com/uciml/forest-cover-type-dataset).\n",
        "\n",
        "Download the dataset in the Google Colab environment using ``curl`` as follows:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbEe8zcsS6UB",
        "colab_type": "code",
        "outputId": "b5fc5298-0645-4a5c-b644-e1f9d5fe0928",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "!curl http://bodini.di.unimi.it/teaching/ADM_files/covtype.csv --output covtype.csv"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 71.6M  100 71.6M    0     0  9337k      0  0:00:07  0:00:07 --:--:-- 17.6M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lbelrq8mTjKw",
        "colab_type": "text"
      },
      "source": [
        "Then, read the .csv file containing the dataset with Pandas as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVgv1Z4mTdXh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('covtype.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I11xn52SUXqg",
        "colab_type": "text"
      },
      "source": [
        "The last column contains the labels, while the other columns contain the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twtCXrI-Uf6i",
        "colab_type": "code",
        "outputId": "31705088-2d27-4075-c94b-5b03dd23dbce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "source": [
        "x = df[df.columns[:-1]]\n",
        "y = df.Cover_Type\n",
        "#print(df)\n",
        "print(x)\n",
        "print(y.drop_duplicates())\n",
        "print(x.shape[1])"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        Elevation  Aspect  Slope  ...  Soil_Type38  Soil_Type39  Soil_Type40\n",
            "0            2596      51      3  ...            0            0            0\n",
            "1            2590      56      2  ...            0            0            0\n",
            "2            2804     139      9  ...            0            0            0\n",
            "3            2785     155     18  ...            0            0            0\n",
            "4            2595      45      2  ...            0            0            0\n",
            "...           ...     ...    ...  ...          ...          ...          ...\n",
            "581007       2396     153     20  ...            0            0            0\n",
            "581008       2391     152     19  ...            0            0            0\n",
            "581009       2386     159     17  ...            0            0            0\n",
            "581010       2384     170     15  ...            0            0            0\n",
            "581011       2383     165     13  ...            0            0            0\n",
            "\n",
            "[581012 rows x 54 columns]\n",
            "0       5\n",
            "2       2\n",
            "40      1\n",
            "1654    7\n",
            "1818    3\n",
            "1868    6\n",
            "1988    4\n",
            "Name: Cover_Type, dtype: int64\n",
            "54\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-QKbh2pTrup",
        "colab_type": "text"
      },
      "source": [
        "Divide the dataset in train and test sets. To compare with my results, set 0.7 as the training set ratio and ``random_state = 90``. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDg0NvwYTod5",
        "colab_type": "code",
        "outputId": "8cd9849a-0d89-4a88-dd7e-a9c6646ec940",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y , train_size = 0.7, random_state = 90)\n",
        "print(x_train.shape,y_train.shape, x_test.shape, y_test.shape)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(406708, 54) (406708,) (174304, 54) (174304,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQRACSRHK0lO",
        "colab_type": "code",
        "outputId": "2ecf2c51-f237-45cf-e006-19eb3deb6591",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "#one-hot encoding for outputs\n",
        "y_train = tf.reshape(tf.one_hot(y_train, 7),[406708, 7])\n",
        "y_test = tf.reshape(tf.one_hot(y_test, 7),[174304, 7])\n",
        "\n",
        "print(y_test, y_train)\n",
        "print(y_train.shape, y_test.shape)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]], shape=(174304, 7), dtype=float32) tf.Tensor(\n",
            "[[0. 0. 1. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]], shape=(406708, 7), dtype=float32)\n",
            "(406708, 7) (174304, 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_e-X7KfA_bQ",
        "colab_type": "code",
        "outputId": "72abe7d6-8f80-4d74-9f86-91da23a7faf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        }
      },
      "source": [
        "#neural network implementation\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(200, activation=\"relu\", input_shape=(x_train.shape[1],)), \n",
        "\n",
        "    keras.layers.Dense(60, activation=\"relu\"), # 2nd hidden layer\n",
        "    keras.layers.BatchNormalization(center=True, scale=False),\n",
        "    keras.layers.Dropout(0.4),\n",
        "\n",
        "    keras.layers.Dense(7, activation=\"softmax\")]) #  output layer with 7 categories\n",
        "  \n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.SGD(lr=0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_45 (Dense)             (None, 200)               11000     \n",
            "_________________________________________________________________\n",
            "dense_46 (Dense)             (None, 60)                12060     \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 60)                180       \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 60)                0         \n",
            "_________________________________________________________________\n",
            "dense_47 (Dense)             (None, 7)                 427       \n",
            "=================================================================\n",
            "Total params: 23,667\n",
            "Trainable params: 23,547\n",
            "Non-trainable params: 120\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeSoNFqdtbN3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 684
        },
        "outputId": "b8a93ceb-4879-44ef-c058-19bd1756248e"
      },
      "source": [
        "history_1 = model.fit(x_train,\n",
        "                    y_train,\n",
        "                    batch_size=100,\n",
        "                    epochs=30,\n",
        "                    validation_data=(x_test,y_test),\n",
        "                    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss')],\n",
        "                    )"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "4068/4068 [==============================] - 13s 3ms/step - loss: 23.9322 - accuracy: 0.4812 - val_loss: 1.2119 - val_accuracy: 0.4880\n",
            "Epoch 2/30\n",
            "4068/4068 [==============================] - 12s 3ms/step - loss: 1.1707 - accuracy: 0.4685 - val_loss: 1.1085 - val_accuracy: 0.4880\n",
            "Epoch 3/30\n",
            "4068/4068 [==============================] - 12s 3ms/step - loss: 1.1209 - accuracy: 0.4691 - val_loss: 1.0865 - val_accuracy: 0.4880\n",
            "Epoch 4/30\n",
            "4068/4068 [==============================] - 12s 3ms/step - loss: 1.1039 - accuracy: 0.4730 - val_loss: 1.0776 - val_accuracy: 0.4880\n",
            "Epoch 5/30\n",
            "4068/4068 [==============================] - 12s 3ms/step - loss: 1.0939 - accuracy: 0.4799 - val_loss: 1.0728 - val_accuracy: 0.4880\n",
            "Epoch 6/30\n",
            "4068/4068 [==============================] - 12s 3ms/step - loss: 1.0881 - accuracy: 0.4826 - val_loss: 1.0697 - val_accuracy: 0.4880\n",
            "Epoch 7/30\n",
            "4068/4068 [==============================] - 12s 3ms/step - loss: 1.0844 - accuracy: 0.4846 - val_loss: 1.0675 - val_accuracy: 0.4880\n",
            "Epoch 8/30\n",
            "4068/4068 [==============================] - 12s 3ms/step - loss: 1.0807 - accuracy: 0.4861 - val_loss: 1.0662 - val_accuracy: 0.4880\n",
            "Epoch 9/30\n",
            "2841/4068 [===================>..........] - ETA: 2s - loss: 1.0772 - accuracy: 0.4876"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-18c00b7a90bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m                     )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    856\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 858\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    859\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    387\u001b[0m     \"\"\"\n\u001b[1;32m    388\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_process_logs\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;34m\"\"\"Turns tensors into numpy arrays or Python scalars.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    517\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    959\u001b[0m     \"\"\"\n\u001b[1;32m    960\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    925\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eDQ5GR6vdXu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "c5f93264-ac66-413a-fd26-354f95abff97"
      },
      "source": [
        "#TASK 2: data normalization\n",
        "x_train_norm = (x_train - x_train.min())/(x_train.max() - x_train.min())\n",
        "x_test_norm = (x_test - x_test.min())/(x_test.max() - x_test.min())\n",
        "print(x_train_norm)\n",
        "print(x_test_norm)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        Elevation    Aspect     Slope  ...  Soil_Type38  Soil_Type39  Soil_Type40\n",
            "152044   0.581791  0.361111  0.166667  ...          0.0          0.0          0.0\n",
            "363373   0.827914  0.286111  0.242424  ...          0.0          0.0          1.0\n",
            "372733   0.399200  0.516667  0.257576  ...          0.0          0.0          0.0\n",
            "572846   0.387694  0.383333  0.181818  ...          0.0          0.0          0.0\n",
            "114145   0.543272  0.700000  0.242424  ...          0.0          0.0          0.0\n",
            "...           ...       ...       ...  ...          ...          ...          ...\n",
            "286827   0.481741  0.966667  0.318182  ...          0.0          0.0          0.0\n",
            "564298   0.351176  0.002778  0.181818  ...          0.0          0.0          0.0\n",
            "402834   0.546773  0.763889  0.196970  ...          0.0          0.0          0.0\n",
            "185125   0.589295  0.069444  0.106061  ...          0.0          0.0          0.0\n",
            "158375   0.531766  0.050000  0.166667  ...          0.0          0.0          0.0\n",
            "\n",
            "[406708 rows x 54 columns]\n",
            "        Elevation    Aspect     Slope  ...  Soil_Type38  Soil_Type39  Soil_Type40\n",
            "204886   0.659125  0.025000  0.112903  ...          0.0          0.0          0.0\n",
            "116027   0.421820  0.119444  0.145161  ...          0.0          0.0          0.0\n",
            "328145   0.510809  0.091667  0.193548  ...          0.0          0.0          0.0\n",
            "579670   0.388638  0.133333  0.177419  ...          0.0          0.0          0.0\n",
            "41341    0.586224  0.661111  0.064516  ...          0.0          0.0          0.0\n",
            "...           ...       ...       ...  ...          ...          ...          ...\n",
            "568345   0.361991  0.958333  0.241935  ...          0.0          0.0          0.0\n",
            "403312   0.647562  0.411111  0.274194  ...          0.0          0.0          0.0\n",
            "494018   0.622423  0.950000  0.306452  ...          0.0          0.0          0.0\n",
            "25785    0.393665  0.002778  0.145161  ...          0.0          0.0          0.0\n",
            "443566   0.648567  0.305556  0.145161  ...          0.0          0.0          0.0\n",
            "\n",
            "[174304 rows x 54 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVH0v8gyviry",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "21d52ad0-e875-4d26-f477-c86a063ff741"
      },
      "source": [
        "history_2 = model.fit(x_train_norm,\n",
        "                    y_train,\n",
        "                    batch_size=100,\n",
        "                    epochs=30,\n",
        "                    validation_data=(x_test_norm,y_test),\n",
        "                    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss')],\n",
        "                    )"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "4068/4068 [==============================] - 14s 3ms/step - loss: 1.0653 - accuracy: 0.5950 - val_loss: 0.6934 - val_accuracy: 0.7022\n",
            "Epoch 2/30\n",
            "4068/4068 [==============================] - 14s 3ms/step - loss: 0.7262 - accuracy: 0.6824 - val_loss: 0.6297 - val_accuracy: 0.7154\n",
            "Epoch 3/30\n",
            "4068/4068 [==============================] - 14s 3ms/step - loss: 0.6752 - accuracy: 0.6942 - val_loss: 0.6004 - val_accuracy: 0.7180\n",
            "Epoch 4/30\n",
            "4068/4068 [==============================] - 14s 3ms/step - loss: 0.6573 - accuracy: 0.6990 - val_loss: 0.5911 - val_accuracy: 0.7214\n",
            "Epoch 5/30\n",
            "4068/4068 [==============================] - 14s 4ms/step - loss: 0.6494 - accuracy: 0.7016 - val_loss: 0.5938 - val_accuracy: 0.7162\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2y_MNKHecXY4",
        "colab_type": "code",
        "outputId": "e896119c-bd75-4ff4-97f5-3c7bfb134e51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "#TASK 3: data rescaling\n",
        "from sklearn import preprocessing\n",
        "\n",
        "#Select numerical columns which needs to be normalized\n",
        "train_norm = x_train[x_train.columns[0:10]]\n",
        "test_norm = x_test[x_test.columns[0:10]]\n",
        "\n",
        "# Normalize Training Data \n",
        "std_scale = preprocessing.StandardScaler().fit(train_norm)\n",
        "x_train_norm = std_scale.transform(train_norm)\n",
        "\n",
        "#Converting numpy array to dataframe\n",
        "training_norm_col = pd.DataFrame(x_train_norm, index=train_norm.index, columns=train_norm.columns) \n",
        "x_train.update(training_norm_col)\n",
        "print (x_train.head())\n",
        "\n",
        "# Normalize Testing Data by using mean and SD of training set\n",
        "x_test_norm = std_scale.transform(test_norm)\n",
        "testing_norm_col = pd.DataFrame(x_test_norm, index=test_norm.index, columns=test_norm.columns) \n",
        "x_test.update(testing_norm_col)\n",
        "print (x_test.head())"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:5732: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self[col] = expressions.where(mask, this, that)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "        Elevation    Aspect     Slope  ...  Soil_Type38  Soil_Type39  Soil_Type40\n",
            "152044   0.222366 -0.228639 -0.412503  ...            0            0            0\n",
            "363373   1.980490 -0.469989  0.255453  ...            0            0            1\n",
            "372733  -1.081933  0.271939  0.389044  ...            0            0            0\n",
            "572846  -1.164122 -0.157128 -0.278912  ...            0            0            0\n",
            "114145  -0.052787  0.861906  0.255453  ...            0            0            0\n",
            "\n",
            "[5 rows x 54 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:5732: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self[col] = expressions.where(mask, this, that)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "        Elevation    Aspect     Slope  ...  Soil_Type38  Soil_Type39  Soil_Type40\n",
            "204886   0.783394 -1.310245 -0.946867  ...            0            0            0\n",
            "116027  -0.903262 -1.006323 -0.679685  ...            0            0            0\n",
            "328145  -0.270766 -1.095711 -0.278912  ...            0            0            0\n",
            "579670  -1.139108 -0.961628 -0.412503  ...            0            0            0\n",
            "41341    0.265247  0.736762 -1.347641  ...            0            0            0\n",
            "\n",
            "[5 rows x 54 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVa1ddXOdFdz",
        "colab_type": "code",
        "outputId": "f35323e9-2b68-4840-b21b-e0d6eac039b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "history_3 = model.fit(x_train,\n",
        "                    y_train,\n",
        "                    batch_size=100,\n",
        "                    epochs=30,\n",
        "                    validation_data=(x_test,y_test),\n",
        "                    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss')],\n",
        "                    )"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "4068/4068 [==============================] - 14s 3ms/step - loss: 0.7374 - accuracy: 0.6677 - val_loss: 0.5969 - val_accuracy: 0.7148\n",
            "Epoch 2/30\n",
            "4068/4068 [==============================] - 14s 3ms/step - loss: 0.6625 - accuracy: 0.6942 - val_loss: 0.5764 - val_accuracy: 0.7218\n",
            "Epoch 3/30\n",
            "4068/4068 [==============================] - 14s 4ms/step - loss: 0.6426 - accuracy: 0.7018 - val_loss: 0.5656 - val_accuracy: 0.7271\n",
            "Epoch 4/30\n",
            "4068/4068 [==============================] - 14s 3ms/step - loss: 0.6308 - accuracy: 0.7072 - val_loss: 0.5610 - val_accuracy: 0.7298\n",
            "Epoch 5/30\n",
            "4068/4068 [==============================] - 14s 3ms/step - loss: 0.6257 - accuracy: 0.7099 - val_loss: 0.5557 - val_accuracy: 0.7331\n",
            "Epoch 6/30\n",
            "4068/4068 [==============================] - 14s 3ms/step - loss: 0.6220 - accuracy: 0.7123 - val_loss: 0.5541 - val_accuracy: 0.7346\n",
            "Epoch 7/30\n",
            "4068/4068 [==============================] - 14s 3ms/step - loss: 0.6231 - accuracy: 0.7126 - val_loss: 0.5523 - val_accuracy: 0.7369\n",
            "Epoch 8/30\n",
            "4068/4068 [==============================] - 15s 4ms/step - loss: 0.6221 - accuracy: 0.7132 - val_loss: 0.5523 - val_accuracy: 0.7373\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}